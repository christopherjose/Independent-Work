{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A computational graph is a series of TenserFlow operations arranged as a graph of nodes.  \n",
    "A node takes in inputs called tensors, which are arrays of rank n \n",
    "(arrays that have n dimensions), and spits out tensors as outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_33:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Const_34:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_35:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "node0 = tf.constant(4)\n",
    "node1 = tf.constant(3.0)\n",
    "node2 = tf.constant(4, tf.float32)\n",
    "print node0\n",
    "print node1\n",
    "print node2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes are evaluated in a **session**, which is an object with a run method that is used to run the computational graph (the nodes aka the series of TenserFlow operations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0, 4.0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run([node1, node2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node3 = tf.add(node1, node2)\n",
    "sess.run(node3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametrize a graph (add parameters to it, whose values are not given until the session is started), by adding **placeholders**.  The documentation calls them parameters, but I like to think of them as variables... promises to provide values later (variables whose values are specified when the session is started or variables that take external inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "[ 5.  7.]\n",
      "18.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "add_node = a+b # a+b is a shortcut for tf.add(a,b)\n",
    "add_and_triple = add_node * 3\n",
    "\n",
    "print sess.run(add_node, {a: 2, b: 4}) #add 2 and 4\n",
    "print sess.run(add_node, {a: [1,2], b: [4,5]})  #[1+4,2+5]\n",
    "print sess.run(add_and_triple, {a:2,b:4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables** are the parameters in our model, whose values we wish to optimize using the training data (aka parameters... lol). <br> **Placeholders** are the variables/predictors/columns in our model.<br>\n",
    "The initial value and type of the variable (trainable parameter) must be given. <br>\n",
    "Constants are initialized with their given values when you create them and stay the same forever. <br>\n",
    "Variables are not initialized with their initial values until you initialize them by doing the special operations shown below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "W=tf.Variable([.3],tf.float32) #Variables are the parameters to optimize\n",
    "b=tf.Variable([-.3],tf.float32) \n",
    "x=tf.placeholder(tf.float32) #Placeholders are the variables that store the data\n",
    "linear_model=W*x+b\n",
    "\n",
    "init = tf.global_variables_initializer() #initializer object \n",
    "sess.run(init) #run the session with the initializer object to initialize all global variables\n",
    "\n",
    "print sess.run(linear_model,{x:[1,2,3,4]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **loss function** is an error metric used to evaluate the model's predictions, like the mean squared error sum((y-yhat)^2).  <br>Let's evaluate this model on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.66"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=tf.placeholder(tf.float32)\n",
    "squared_deltas=tf.square(y-linear_model) #creates vector of squared error deltas (y-yhat)\n",
    "loss=tf.reduce_sum(squared_deltas) #sums tensor elements (squared error deltas)\n",
    "sess.run(loss, {x:[1,2,3,4],y:[0,-1,-2,-3]}) #run session which evaluates loss func of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the values of variables after they have been initialized by doing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1.], dtype=float32), array([ 1.], dtype=float32)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixW = tf.assign(W,[-1.]) #re-assign parameter value W to -1\n",
    "fixb = tf.assign(b,[1.])\n",
    "sess.run([fixW,fixb]) #take re-assingment objects and evaluate them using run method\n",
    "sess.run(loss, {x:[1,2,3,4],y:[0,-1,-2,-3]}) #evaluate the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow has **optimizers** which slowly change the value of each variable in order to minimize the loss function.  The simplest optimizer is **gradient descent**, which modifies each variable according to the magnitude of the derivative of loss with respect to that variable. <br>\n",
    "\n",
    "The **minimize()** method of the optimizer performs two steps: <br>\n",
    "1) It runs compute_gradients() and returns a list of (gradient, variable) pairs where a gradient is a partial derivative <br>\n",
    "2) It runs apply_gradients() to apply the gradients to the variable coefficients\n",
    "such that (this is what I believe is happening...) coefficient = coefficient â€“ (learning rate * gradient).  So the coefficients are revised from their old values upon each iteration of the method (when the session is run with the optimizer object and training data multiple times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(.01) #select optimizer with learning rate = .01\n",
    "train = optimizer.minimize(loss) \n",
    "#create object of optimizer's minimize method on specified loss func \n",
    "sess.run(init) #reset values to un-optimal defaults\n",
    "for i in range(0,1000):\n",
    "    sess.run(train,{x:[1,2,3,4], y:[0,-1,-2,-3]})\n",
    "print sess.run([W,b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Algorithm for Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n",
      "W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "#parameters\n",
    "W=tf.Variable([.3],tf.float32)\n",
    "b=tf.Variable([-.3],tf.float32)\n",
    "\n",
    "#variables\n",
    "x=tf.placeholder(tf.float32)\n",
    "y=tf.placeholder(tf.float32)\n",
    "\n",
    "#model\n",
    "linear_model=W*x+b\n",
    "\n",
    "#data\n",
    "x_train=[1,2,3,4]\n",
    "y_train=[0,-1,-2,-3]\n",
    "\n",
    "#loss function\n",
    "loss=tf.reduce_sum(tf.square(y-linear_model) ) \n",
    "\n",
    "#optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(.01) \n",
    "train = optimizer.minimize(loss) \n",
    "\n",
    "#training loop\n",
    "init = tf.global_variables_initializer() \n",
    "sess.run(init) \n",
    "for i in range(0,1000):\n",
    "    sess.run(train,{x:x_train, y:y_train})\n",
    "print sess.run([W,b])\n",
    "\n",
    "#results\n",
    "curr_W, curr_b, curr_loss  = sess.run([W, b, loss], {x:x_train, y:y_train})\n",
    "print \"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Udacity tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "hello_constant = tf.constant('Hello World!')\n",
    "with tf.Session() as sess:  #within this session, run the following indented code\n",
    "    output = sess.run(hello_constant)\n",
    "    print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#constants \n",
    "hello_constant = tf.constant('Hello World!') #A 0-Dimensional string tensor\n",
    "A=tf.constant(123) # A 0-D int32 tensor\n",
    "B=tf.constant([123,456,789]) # A 1-D int32 tensor\n",
    "C=tf.constant([[123,456,789],[222,333,444]]) # A 2-D int32 tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Placeholders are input data that doesn't change as your model is trained over time. <br> tf.placeholder() returns a tensor that gets its value from data passed to the tf.session.run() function.  Initial values aren't specified.  Values are specified at run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "#placeholders (values must be feed using the feed_dict argument of Session.run()\n",
    "x = tf.placeholder(tf.string)\n",
    "y = tf.placeholder(tf.int32)\n",
    "r = tf.placeholder(tf.int32)\n",
    "z = tf.add(y,r)\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(z,feed_dict={x:'test',y:52,r:10})\n",
    "    print output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sess.run(output variable,feed_dict={input var 1: values, input var 2: values}** <br>\n",
    "The first argument is the variable whose values will be outputed based on the input var values (assuming it's value is linked).  Notice above how x's input value is irrelevant given that the output variable z only dependings on y and r."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic operations must involve data of the same type.  Use cast() to convert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#arithmetic operations; tf.add(), tf.multiply(), tf.divide()\n",
    "#you can't do operations between un-like data types, so convert using cast     \n",
    "tf.constant(2.0)-tf.cast(tf.constant(2), tf.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "#Convert x/y  - 1  to tensorflow.\n",
    "x = tf.constant(10,tf.int32)\n",
    "y = tf.constant(2,tf.int32)\n",
    "z = tf.subtract(tf.divide(x,y), tf.cast(tf.constant(1), tf.float64))\n",
    "#division of two int32s results in a float64\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(z)\n",
    "    print output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables are tensors whose value changes over time.  They are the parameters you are optimizing in the model.  You must specify them with initial values and then initialize them all with a command.  In a neural network, these are the weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.44390768, -0.61203152,  0.23738734],\n",
       "       [ 0.87302935,  0.16142465, -0.73896587]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.],\n",
       "       [ 1.,  1.],\n",
       "       [ 1.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.81855184, -0.81855184],\n",
       "       [ 0.29548812,  0.29548812]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=tf.Variable(tf.truncated_normal((2, 3))) \n",
    "c=tf.Variable(tf.ones((3, 2))) \n",
    "e=tf.matmul(d,c) #matrix multiplication (you can't use tf.multiply() for matrices)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(d)\n",
    "    sess.run(c)\n",
    "    sess.run(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8778612000000001"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.30829522*1+1.1575352+0.02862122 #this matches [0,0] of output matrix e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.53394204, -0.24607509],\n",
       "        [-0.8625955 ,  0.77668595],\n",
       "        [ 0.30873638,  0.15395114],\n",
       "        [-1.70844173,  1.19698119],\n",
       "        [ 1.36034513, -0.75936306]],\n",
       "\n",
       "       [[ 0.24787042,  0.04737306],\n",
       "        [-0.89776468, -0.31662938],\n",
       "        [-1.02188563, -0.56089604],\n",
       "        [ 0.90292042,  0.66548216],\n",
       "        [ 1.73288608, -0.06248853]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=tf.Variable(tf.truncated_normal((2, 5,2))) \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15133592,  0.44067106],\n",
       "       [-1.28744531,  0.0758683 ]], dtype=float32)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.68945396],\n",
       "       [ 0.61692977]], dtype=float32)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.01618803,  0.01618803,  0.01618803],\n",
       "       [-2.1282742 , -2.1282742 , -2.1282742 ]], dtype=float32)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#variables must be initialized (with initial values) before they can be used\n",
    "random_data=tf.Variable(tf.truncated_normal((2,2))) #\n",
    "weights=tf.Variable(tf.truncated_normal((2, 1))) #\n",
    "bias=tf.Variable(tf.zeros(3)) #tf.zeros generates 3 zeros\n",
    "results=tf.add(tf.matmul(random_data,weights),bias)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) \n",
    "sess.run(random_data)\n",
    "sess.run(weights)\n",
    "sess.run(bias)\n",
    "sess.run(results)             #this will return an error if the variable is not initialized         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016188026357213003"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.15133592*1.68945396+0.44067106*0.61692977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alternatively, below seems to highlight that all indented actions belong to this session \n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    sess.run(bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.truncated_normal((5, 10) produces a matrix of 5 rows and 10 columns of random values in a truncated normal distribution, where values cannot exceed 2 standard deviations from the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a softmax function, which converts logit values (log-odds) to probabilities in the output layer of a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.65900117,  0.24243298,  0.09856589], dtype=float32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run():\n",
    "    output = None\n",
    "    logits = tf.placeholder(tf.float32) #placeholder for input data that we'll feed into sess \n",
    "    softmax =  tf.nn.softmax(logits)    #function that depends on value of logits placeholder\n",
    "                                        #this will be the output variable \n",
    "    logit_data = [2.0, 1.0, 0.1] #input data\n",
    "\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        output = sess.run(softmax, feed_dict={logits:logit_data})\n",
    "    return output\n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the cross-entropy cost function (for classification) using softmax probabilities and one-hot encoded labels of those probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross-entropy for one observation <br>\n",
    "cross-entropy = -log(y-hat) for the true label <br>\n",
    "cross-entropy =  - sum [  log(softmax prob j)  x one-hot-encoded label aka 1s 0s ]  <br>\n",
    "cross-entropy =  - sum [  log(predicted prob)  x actual y label ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pictures/cross-entropy-diagram.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.356675\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "softmax_data = [0.7, 0.2, 0.1] #y-hat\n",
    "one_hot_data = [1.0, 0.0, 0.0] #y\n",
    "\n",
    "softmax = tf.placeholder(tf.float32)\n",
    "one_hot = tf.placeholder(tf.float32)\n",
    "cross_entropy=-tf.reduce_sum(tf.multiply(one_hot,tf.log(softmax)))\n",
    "\n",
    "#Print cross entropy from session\n",
    "with tf.Session() as sess:\n",
    "    output=sess.run(cross_entropy,feed_dict={softmax:softmax_data,one_hot:one_hot_data})\n",
    "print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953674316406\n"
     ]
    }
   ],
   "source": [
    "a = 1000000000\n",
    "for i in range(1000000):\n",
    "    a = a + 1e-6\n",
    "print a - 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "30\n",
      "60\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "for j in range(0,100,30):\n",
    "    print j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def batches(batch_size, features, labels):\n",
    "\n",
    "    assert len(features) == len(labels)\n",
    "    # TODO: Implement batching\n",
    "    output_batches = []\n",
    "    \n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        output_batches.append(batch)\n",
    "        \n",
    "    return output_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['F41', 'F42', 'F43', 'F44']], [['L41', 'L42']]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 Samples of features\n",
    "example_features = [\n",
    "    ['F11','F12','F13','F14'],\n",
    "    ['F21','F22','F23','F24'],\n",
    "    ['F31','F32','F33','F34'],\n",
    "    ['F41','F42','F43','F44']]\n",
    "# 4 Samples of labels\n",
    "example_labels = [\n",
    "    ['L11','L12'],\n",
    "    ['L21','L22'],\n",
    "    ['L31','L32'],\n",
    "    ['L41','L42']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting .../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting .../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting .../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting .../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('.../MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = mnist.train.images\n",
    "test_features = mnist.test.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000    616\n",
       "0.996078     53\n",
       "0.921569      7\n",
       "0.239216      6\n",
       "0.984314      4\n",
       "0.780392      4\n",
       "0.917647      3\n",
       "0.807843      3\n",
       "0.894118      3\n",
       "0.458824      3\n",
       "0.329412      3\n",
       "0.992157      2\n",
       "0.349020      2\n",
       "0.450980      2\n",
       "0.545098      2\n",
       "0.945098      2\n",
       "0.266667      2\n",
       "0.949020      2\n",
       "0.082353      2\n",
       "0.741176      2\n",
       "0.223529      2\n",
       "0.615686      2\n",
       "0.843137      1\n",
       "0.294118      1\n",
       "0.160784      1\n",
       "0.149020      1\n",
       "0.835294      1\n",
       "0.658824      1\n",
       "0.415686      1\n",
       "0.933333      1\n",
       "           ... \n",
       "0.862745      1\n",
       "0.188235      1\n",
       "0.015686      1\n",
       "0.733333      1\n",
       "0.980392      1\n",
       "0.972549      1\n",
       "0.090196      1\n",
       "0.964706      1\n",
       "0.960784      1\n",
       "0.352941      1\n",
       "0.952941      1\n",
       "0.941177      1\n",
       "0.690196      1\n",
       "0.937255      1\n",
       "0.466667      1\n",
       "0.443137      1\n",
       "0.050980      1\n",
       "0.462745      1\n",
       "0.337255      1\n",
       "0.243137      1\n",
       "0.662745      1\n",
       "0.905882      1\n",
       "0.098039      1\n",
       "0.650980      1\n",
       "0.321569      1\n",
       "0.745098      1\n",
       "0.019608      1\n",
       "0.874510      1\n",
       "0.870588      1\n",
       "0.890196      1\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(train_features).loc[0,:].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006737946999085467"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.exp(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network output:\n",
      "0.689974481128\n",
      "Amount of Error:\n",
      "-0.189974481128\n",
      "Change in Weights:\n",
      "[-0.020318691802303994, -0.040637383604607988, -0.060956075406911982, -0.081274767209215976]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    \"\"\"\n",
    "    # Derivative of the sigmoid function\n",
    "    \"\"\"\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "learnrate = 0.5\n",
    "x = np.array([1, 2, 3, 4])\n",
    "y = np.array(0.5)\n",
    "\n",
    "# Initial weights\n",
    "w = np.array([0.5, -0.5, 0.3, 0.1])\n",
    "\n",
    "### Calculate one gradient descent step for each weight\n",
    "### Note: Some steps have been consilated, so there are\n",
    "###       fewer variable names than in the above sample code\n",
    "\n",
    "# TODO: Calculate the node's linear combination of inputs and weights\n",
    "import numpy as np\n",
    "h = np.dot(x,w)\n",
    "\n",
    "# TODO: Calculate output of neural network\n",
    "nn_output = sigmoid(h)\n",
    "\n",
    "# TODO: Calculate error of neural network\n",
    "error = (y-sigmoid(h))\n",
    "\n",
    "# TODO: Calculate the error term\n",
    "#       Remember, this requires the output gradient, which we haven't\n",
    "#       specifically added a variable for.\n",
    "error_term = error*sigmoid_prime(h)\n",
    "\n",
    "# TODO: Calculate change in weights\n",
    "del_w = [learnrate* error_term * x[0],\n",
    "          learnrate* error_term * x[1],\n",
    "          learnrate* error_term * x[2],\n",
    "          learnrate* error_term * x[3]]\n",
    "\n",
    "print('Neural Network output:')\n",
    "print(nn_output)\n",
    "print('Amount of Error:')\n",
    "print(error)\n",
    "print('Change in Weights:')\n",
    "print(del_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.28183395 -0.308662   -0.44758153]\n",
      " [-0.80714601 -0.29025713  0.51695603]]\n",
      "\n",
      "[-1.6614666  -0.94179952 -0.38951397]\n"
     ]
    }
   ],
   "source": [
    "weights = tf.Variable(tf.truncated_normal([2, 3],seed=1))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(weights))\n",
    "    print('')\n",
    "    print(sess.run(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
